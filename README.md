# NotebookLM Mini Clone ğŸ“šğŸ¤–

A powerful RAG (Retrieval-Augmented Generation) application built with Next.js that mimics Google's NotebookLM functionality. Upload documents, ask questions, and get AI-powered insights from your knowledge base.

![NotebookLM Mini Clone](https://img.shields.io/badge/Status-Production%20Ready-brightgreen)
![Next.js](https://img.shields.io/badge/Next.js-15.4.7-000000?logo=nextdotjs)
![Node.js](https://img.shields.io/badge/Node.js-18+-339933?logo=nodedotjs)
![License](https://img.shields.io/badge/License-MIT-blue)

## âœ¨ Features

### ğŸ”„ Document Processing

- **PDF Documents** - Extract and process text from PDF files
- **CSV Files** - Parse and structure CSV data for querying
- **Text Files** - Direct text document upload (.txt, .md)
- **URL Ingestion** - Extract content from web pages using Readability

### ğŸ§  AI-Powered Chat

- **Contextual Responses** - AI answers based on your uploaded documents
- **Streaming Chat** - Real-time response streaming for better UX
- **Document Summarization** - Get quick summaries of your knowledge base
- **Source Attribution** - Track which documents inform each response

### ğŸ¨ Modern UI/UX

- **Dark Theme** - Eye-friendly dark interface
- **Fully Responsive** - Optimized for desktop, tablet, and mobile (320px+)
- **Drag & Drop** - Intuitive file upload experience
- **Tab Navigation** - Organized upload interface for different content types

### ğŸ›  Technical Features

- **Vector Search** - Semantic similarity search using OpenAI embeddings
- **Chunking Strategy** - Smart text splitting with overlap for context preservation
- **Docker Integration** - Containerized Qdrant vector database
- **Environment Configuration** - Flexible setup for different environments

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   Vector DB     â”‚
â”‚   (Next.js)     â”‚â—„â”€â”€â–ºâ”‚   (API Routes)  â”‚â—„â”€â”€â–ºâ”‚   (Qdrant)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚                       â”‚
        â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   OpenAI API    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚   (GPT-4o-mini) â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tech Stack

- **Frontend**: Next.js 15, React, TailwindCSS
- **Backend**: Next.js API Routes, Node.js
- **AI/ML**: OpenAI GPT-4o-mini, LangChain.js, OpenAI Embeddings
- **Vector Database**: Qdrant (Docker)
- **Document Processing**: pdf-parse, papaparse, jsdom, readability

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ installed
- Docker and Docker Compose installed
- OpenAI API key

### Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/Kanishk2004/rag_application.git
   cd rag_application
   ```

2. **Install dependencies**

   ```bash
   npm install
   ```

3. **Set up environment variables**

   ```bash
   # Copy the environment template
   cp .env .env.local

   # Add your OpenAI API key to .env.local
   OPENAI_API_KEY=sk-your-openai-api-key-here
   QDRANT_URL=http://localhost:6333
   NEXT_PUBLIC_APP_URL=http://localhost:3000
   ```

4. **Start Qdrant vector database**

   ```bash
   docker-compose up -d
   ```

5. **Run the development server**

   ```bash
   npm run dev
   ```

6. **Open your browser**
   Navigate to [http://localhost:3000](http://localhost:3000)

## ğŸ“– Usage Guide

### 1. Upload Documents

- **File Upload**: Drag and drop or select PDF, CSV, or text files
- **Direct Text**: Paste text directly into the application
- **URL Import**: Enter a webpage URL to extract and process its content

### 2. Ask Questions

- Once documents are uploaded, use the chat interface
- Ask questions about your uploaded content
- Get AI-powered responses with source attribution

### 3. Document Summarization

- Click "Summarize Documents" to get an overview of your knowledge base
- Useful for understanding large document collections

## ğŸ— Project Structure

```
rag_application/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                    # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ api/               # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ chat/         # Chat completion endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest/       # Document upload endpoint
â”‚   â”‚   â”‚   â””â”€â”€ summarize/    # Summarization endpoint
â”‚   â”‚   â”œâ”€â”€ app/              # Main application page
â”‚   â”‚   â”œâ”€â”€ globals.css       # Global styles
â”‚   â”‚   â”œâ”€â”€ layout.js         # Root layout
â”‚   â”‚   â””â”€â”€ page.js           # Landing page
â”‚   â”œâ”€â”€ components/            # React components
â”‚   â”‚   â”œâ”€â”€ Chat.js           # Chat interface
â”‚   â”‚   â””â”€â”€ UploadZone.js     # File upload component
â”‚   â””â”€â”€ lib/                  # Utility libraries
â”‚       â”œâ”€â”€ langchain.js      # LangChain configuration
â”‚       â”œâ”€â”€ loaders.js        # Document processing
â”‚       â””â”€â”€ qdrant.js         # Vector database operations
â”œâ”€â”€ public/                    # Static assets
â”œâ”€â”€ docs/                      # Documentation
â”œâ”€â”€ tests/                     # Test files
â”œâ”€â”€ docker-compose.yml         # Docker configuration
â””â”€â”€ package.json              # Dependencies
```

## ğŸ”§ Configuration

### Environment Variables

| Variable              | Description         | Required    |
| --------------------- | ------------------- | ----------- |
| `OPENAI_API_KEY`      | Your OpenAI API key | âœ… Yes      |
| `QDRANT_URL`          | Qdrant database URL | âœ… Yes      |
| `NEXT_PUBLIC_APP_URL` | Application URL     | âŒ Optional |

### Qdrant Configuration

The vector database runs in Docker with the following settings:

- **Port**: 6333
- **Collection**: notebooklm_mini
- **Vector Size**: 3072 (text-embedding-3-large)
- **Distance**: Cosine similarity

### Text Processing

- **Chunk Size**: 1200 characters
- **Chunk Overlap**: 200 characters
- **Separators**: Double newline, newline, space

## ğŸš€ Deployment

### Docker Deployment

```bash
# Build and start all services
docker-compose up -d

# View logs
docker-compose logs -f
```

### Production Environment

1. Set `NODE_ENV=production`
2. Configure production OpenAI API key
3. Use production-ready Qdrant instance
4. Set up proper SSL/TLS termination

## ğŸ§ª API Documentation

### POST /api/ingest

Upload and process documents

```javascript
// File upload
const formData = new FormData();
formData.append('file', file);
formData.append('type', 'file');

// Text input
const response = await fetch('/api/ingest', {
	method: 'POST',
	headers: { 'Content-Type': 'application/json' },
	body: JSON.stringify({ type: 'text', content: 'Your text here' }),
});
```

### POST /api/chat

Chat with your documents

```javascript
const response = await fetch('/api/chat', {
	method: 'POST',
	headers: { 'Content-Type': 'application/json' },
	body: JSON.stringify({ message: 'What is this document about?' }),
});
```

### GET /api/summarize

Get document summary

```javascript
const response = await fetch('/api/summarize');
const { summary } = await response.json();
```

## ğŸ›  Development

### Available Scripts

- `npm run dev` - Start development server
- `npm run build` - Build for production
- `npm run start` - Start production server
- `npm run lint` - Run ESLint

### Adding New Document Types

1. Extend the `processFile` function in `src/lib/loaders.js`
2. Add file type detection logic
3. Implement parsing for the new format
4. Update the upload UI to accept the new file type

### Customizing AI Responses

Modify the system prompt in `src/lib/langchain.js`:

```javascript
const systemPrompt = 'Your custom system prompt here...';
```

## ğŸ” Troubleshooting

### Common Issues

**Error: Missing OpenAI API key**

- Ensure `OPENAI_API_KEY` is set in `.env.local`
- Verify the API key is valid and has sufficient credits

**Error: Cannot connect to Qdrant**

- Check if Docker is running: `docker ps`
- Start Qdrant: `docker-compose up -d`
- Verify port 6333 is not in use

**Upload fails with 500 error**

- Check server logs in the terminal
- Ensure all environment variables are set
- Verify file format is supported

**Chat responses are slow**

- OpenAI API can be slow during peak times
- Consider upgrading to a paid OpenAI plan
- Check your internet connection

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ï¿½â€ğŸ’» Developer

This project was developed by **Kanishk Chandna**, a passionate full-stack developer specializing in AI-powered applications and modern web technologies.

### ğŸ“« Connect with me:

- **Portfolio**: [https://www.kanishk.codes](https://www.kanishk.codes)
- **LinkedIn**: [https://www.linkedin.com/in/kanishk-chandna-9553931b0/](https://www.linkedin.com/in/kanishk-chandna-9553931b0/)
- **Twitter**: [https://x.com/Kanishk_fr](https://x.com/Kanishk_fr)
- **Email**: [kanishkchandna29@gmail.com](mailto:kanishkchandna29@gmail.com)
- **Phone**: +91 9268815903

### ğŸ’¼ About

Experienced in building scalable web applications with React/Next.js, Node.js, AI/ML integration, and modern cloud technologies. Always excited to collaborate on innovative projects and contribute to the developer community.

## ï¿½ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Google NotebookLM** - Inspiration for the UI and functionality
- **OpenAI** - For providing the GPT and embedding APIs
- **LangChain** - For the excellent RAG framework
- **Qdrant** - For the high-performance vector database
- **Vercel** - For Next.js and deployment platform

## ğŸ“ Support

If you encounter any issues or have questions:

1. Check the [troubleshooting section](#-troubleshooting)
2. Look through existing [GitHub issues](../../issues)
3. Create a new issue with detailed information

---

**Built with â¤ï¸ using Next.js and AI**

_Transform your documents into an intelligent knowledge base_
